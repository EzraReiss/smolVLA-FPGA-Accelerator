{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Text Encoder Roofline Analysis\n",
                "\n",
                "This notebook provides a detailed breakdown of the compute and memory requirements for the **Text Encoder** (Language Model) of the smolVLA model on the Alveo U280 FPGA.\n",
                "\n",
                "**Objective**: Analyze individual kernels to identify bottlenecks and guide acceleration strategies.\n",
                "\n",
                "## 1. Hardware Specifications (Alveo U280)\n",
                "*   **Frequency**: 300 MHz\n",
                "*   **Peak Bandwidth**: 460 GB/s (Theoretical), 300 GB/s (Realistic)\n",
                "*   **Peak Compute**:\n",
                "    *   FP32: 5.41 TFLOPs\n",
                "    *   INT8: 18.6 TOPS\n",
                "    *   INT4: 37.2 TOPS"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "\n",
                "plt.style.use('seaborn-v0_8-paper')\n",
                "plt.rcParams.update({'font.size': 12, 'figure.dpi': 150})\n",
                "%matplotlib inline\n",
                "\n",
                "# Hardware Specs\n",
                "FREQ = 300e6\n",
                "BW_REAL = 300e9\n",
                "P_FP32 = 5.41e12\n",
                "P_INT8 = 18.6e12\n",
                "P_INT4 = 37.2e12\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Model Dimensions (Text Encoder)\n",
                "Derived from `model_shape.txt`.\n",
                "\n",
                "*   **Hidden Dim ($D$)**: 960\n",
                "*   **FFN Dim**: 2560\n",
                "*   **Layers**: 16\n",
                "*   **Attention (GQA)**:\n",
                "    *   $Q_{dim} = 960$\n",
                "    *   $K_{dim} = 320$\n",
                "    *   $V_{dim} = 320$\n",
                "    *   $Out_{dim} = 960$\n",
                "*   **Sequence Length ($S$)**: 50 (Typical text query)\n",
                "*   **Batch Size ($B$)**: 1"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "B = 1\n",
                "S = 50\n",
                "D = 960\n",
                "FFN = 2560\n",
                "Q_D = 960\n",
                "K_D = 320\n",
                "V_D = 320\n",
                "OUT_D = 960\n",
                "\n",
                "# Precision (Bytes)\n",
                "precisions = {'FP32': 4, 'BF16': 2, 'INT8': 1, 'INT4': 0.5}\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Kernel Analysis\n",
                "\n",
                "We calculate FLOPs, Memory Transfer (Bytes), and Operational Intensity (OI) for each kernel type.\n",
                "\n",
                "**Formula**:\n",
                "*   $FLOPs = 2 \\times M \\times K \\times N$\n",
                "*   $Bytes = (M \\times K + K \\times N + M \\times N) \\times \\text{dtype\\_size}$\n",
                "*   $OI = FLOPs / Bytes$"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def analyze_kernel(name, M, K, N, p_bytes):\n",
                "    flops = 2 * M * K * N\n",
                "    # Weights (K*N) + Input (M*K) + Output (M*N)\n",
                "    mem_weights = K * N * p_bytes\n",
                "    mem_io = (M * K + M * N) * p_bytes\n",
                "    total_bytes = mem_weights + mem_io\n",
                "    oi = flops / total_bytes\n",
                "    return {\n",
                "        'Kernel': name,\n",
                "        'M': M, 'K': K, 'N': N,\n",
                "        'FLOPs': flops,\n",
                "        'Bytes': total_bytes,\n",
                "        'OI': oi,\n",
                "        'Weight_MB': mem_weights / 1e6\n",
                "    }\n",
                "\n",
                "data = []\n",
                "p_name = 'INT8' # Baseline for detailed table\n",
                "p_bytes = precisions[p_name]\n",
                "\n",
                "# 1. Attention Q Projection\n",
                "# M=S(50), K=D(960), N=Q_D(960)\n",
                "data.append(analyze_kernel('Attn_Q', S, D, Q_D, p_bytes))\n",
                "\n",
                "# 2. Attention K Projection (Smaller)\n",
                "# M=S(50), K=D(960), N=K_D(320)\n",
                "data.append(analyze_kernel('Attn_K', S, D, K_D, p_bytes))\n",
                "\n",
                "# 3. Attention V Projection (Smaller)\n",
                "# M=S(50), K=D(960), N=V_D(320)\n",
                "data.append(analyze_kernel('Attn_V', S, D, V_D, p_bytes))\n",
                "\n",
                "# 4. Attention Output Projection\n",
                "# M=S(50), K=D(960), N=D(960)\n",
                "data.append(analyze_kernel('Attn_Out', S, D, OUT_D, p_bytes))\n",
                "\n",
                "# 5. MLP Gate/Up Projections\n",
                "# M=S(50), K=D(960), N=FFN(2560)\n",
                "data.append(analyze_kernel('MLP_Gate', S, D, FFN, p_bytes))\n",
                "data.append(analyze_kernel('MLP_Up', S, D, FFN, p_bytes))\n",
                "\n",
                "# 6. MLP Down Projection\n",
                "# M=S(50), K=FFN(2560), N=D(960)\n",
                "data.append(analyze_kernel('MLP_Down', S, FFN, D, p_bytes))\n",
                "\n",
                "# 7. LM Head\n",
                "# M=1 (Last Token), K=D(960), N=Vocab(49280)\n",
                "data.append(analyze_kernel('LM_Head', 1, D, 49280, p_bytes))\n",
                "\n",
                "df = pd.DataFrame(data)\n",
                "print(f\"--- Kernel Metrics ({p_name}) ---\")\n",
                "display(df[['Kernel', 'FLOPs', 'Bytes', 'OI', 'Weight_MB']].round(2))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Roofline Plot\n",
                "\n",
                "We plot these kernels on the Roofline model to visualize their performance limitations."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def plot_roofline(df_metrics):\n",
                "    fig, ax = plt.subplots(figsize=(12, 8))\n",
                "    x = np.logspace(-2, 3, 100)\n",
                "    \n",
                "    # Ceilings\n",
                "    ax.loglog(x, np.minimum(P_FP32, BW_REAL * x), 'k-', label='FP32 Peak')\n",
                "    ax.loglog(x, np.minimum(P_INT8, BW_REAL * x), 'b-', label='INT8 Peak')\n",
                "    ax.loglog(x, np.minimum(P_INT4, BW_REAL * x), 'g-', label='INT4 Peak')\n",
                "    ax.loglog(x, BW_REAL * x, 'r--', label='Memory Wall')\n",
                "    \n",
                "    # Plot Kernels (INT8 Baseline)\n",
                "    for i, (_, row) in enumerate(df_metrics.iterrows()):\n",
                "        oi = row['OI']\n",
                "        # Calculate perf for INT8\n",
                "        perf = min(P_INT8, BW_REAL * oi)\n",
                "        ax.plot(oi, perf, 'b^', markersize=12)\n",
                "        \n",
                "        # Offset labels to avoid overlap\n",
                "        # Alternating vertical offset\n",
                "        offset = 1.3 if i % 2 == 0 else 0.7\n",
                "        ax.text(oi, perf * offset, row['Kernel'], fontsize=9, ha='center', va='bottom' if offset > 1 else 'top')\n",
                "        \n",
                "    ax.set_xlabel('Operational Intensity (Ops/Byte)')\n",
                "    ax.set_ylabel('Performance (Ops/s)')\n",
                "    ax.set_title('Text Encoder Roofline (INT8)')\n",
                "    ax.grid(True, which=\"both\", ls=\"-\", alpha=0.5)\n",
                "    ax.legend()\n",
                "    plt.show()\n",
                "\n",
                "plot_roofline(df)\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}